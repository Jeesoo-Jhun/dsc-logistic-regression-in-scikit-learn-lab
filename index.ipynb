{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression in scikit-learn - Lab\n","\n","## Introduction \n","\n","In this lab, you are going to fit a logistic regression model to a dataset concerning heart disease. Whether or not a patient has heart disease is indicated in the column labeled `'target'`. 1 is for positive for heart disease while 0 indicates no heart disease.\n","\n","## Objectives\n","\n","In this lab you will: \n","\n","- Fit a logistic regression model using scikit-learn \n","\n","\n","## Let's get started!\n","\n","Run the following cells that import the necessary functions and import the dataset: "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import necessary functions\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>233</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>250</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>187</td>\n","      <td>0</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>204</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>178</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   63    1   3       145   233    1        0      150      0      2.3      0   \n","1   37    1   2       130   250    0        1      187      0      3.5      0   \n","2   41    0   1       130   204    0        0      172      0      1.4      2   \n","3   56    1   1       120   236    0        1      178      0      0.8      2   \n","4   57    0   0       120   354    0        1      163      1      0.6      2   \n","\n","   ca  thal  target  \n","0   0     1       1  \n","1   0     2       1  \n","2   0     2       1  \n","3   0     2       1  \n","4   0     2       1  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Import data\n","df = pd.read_csv('heart.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Define appropriate `X` and `y` \n","\n","Recall the dataset contains information about whether or not a patient has heart disease and is indicated in the column labeled `'target'`. With that, define appropriate `X` (predictors) and `y` (target) in order to model whether or not a patient has heart disease."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Split the data into target and predictors\n","y = df['target']\n","X = df.drop(columns=['target'])"]},{"cell_type":"markdown","metadata":{},"source":["## Train- test split \n","\n","- Split the data into training and test sets \n","- Assign 25% to the test set \n","- Set the `random_state` to 0 \n","\n","N.B. To avoid possible data leakage, it is best to split the data first, and then normalize."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Normalize the data \n","\n","Normalize the data (`X`) prior to fitting the model. "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.352565</td>\n","      <td>0.702439</td>\n","      <td>0.987029</td>\n","      <td>0.020206</td>\n","      <td>-0.435970</td>\n","      <td>-0.426956</td>\n","      <td>-0.982565</td>\n","      <td>1.011893</td>\n","      <td>-0.723526</td>\n","      <td>1.724840</td>\n","      <td>0.962226</td>\n","      <td>1.227233</td>\n","      <td>1.121359</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.310686</td>\n","      <td>0.702439</td>\n","      <td>-0.919827</td>\n","      <td>-1.140980</td>\n","      <td>-0.325394</td>\n","      <td>-0.426956</td>\n","      <td>0.891740</td>\n","      <td>0.453640</td>\n","      <td>-0.723526</td>\n","      <td>-0.923487</td>\n","      <td>0.962226</td>\n","      <td>0.259935</td>\n","      <td>-0.459688</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.089602</td>\n","      <td>0.702439</td>\n","      <td>0.987029</td>\n","      <td>1.065272</td>\n","      <td>-0.288536</td>\n","      <td>-0.426956</td>\n","      <td>-0.982565</td>\n","      <td>0.668352</td>\n","      <td>-0.723526</td>\n","      <td>0.400676</td>\n","      <td>0.962226</td>\n","      <td>-0.707364</td>\n","      <td>1.121359</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.463107</td>\n","      <td>0.702439</td>\n","      <td>1.940457</td>\n","      <td>2.690932</td>\n","      <td>0.411776</td>\n","      <td>-0.426956</td>\n","      <td>-0.982565</td>\n","      <td>-0.190498</td>\n","      <td>-0.723526</td>\n","      <td>2.552442</td>\n","      <td>-2.273704</td>\n","      <td>-0.707364</td>\n","      <td>1.121359</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.347442</td>\n","      <td>0.702439</td>\n","      <td>-0.919827</td>\n","      <td>-0.676506</td>\n","      <td>-0.343823</td>\n","      <td>-0.426956</td>\n","      <td>-0.982565</td>\n","      <td>-0.877579</td>\n","      <td>1.382120</td>\n","      <td>1.228278</td>\n","      <td>-0.655739</td>\n","      <td>1.227233</td>\n","      <td>1.121359</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age       sex        cp  trestbps      chol       fbs   restecg  \\\n","0  0.352565  0.702439  0.987029  0.020206 -0.435970 -0.426956 -0.982565   \n","1 -0.310686  0.702439 -0.919827 -1.140980 -0.325394 -0.426956  0.891740   \n","2 -0.089602  0.702439  0.987029  1.065272 -0.288536 -0.426956 -0.982565   \n","3  0.463107  0.702439  1.940457  2.690932  0.411776 -0.426956 -0.982565   \n","4  1.347442  0.702439 -0.919827 -0.676506 -0.343823 -0.426956 -0.982565   \n","\n","    thalach     exang   oldpeak     slope        ca      thal  \n","0  1.011893 -0.723526  1.724840  0.962226  1.227233  1.121359  \n","1  0.453640 -0.723526 -0.923487  0.962226  0.259935 -0.459688  \n","2  0.668352 -0.723526  0.400676  0.962226 -0.707364  1.121359  \n","3 -0.190498 -0.723526  2.552442 -2.273704 -0.707364  1.121359  \n","4 -0.877579  1.382120  1.228278 -0.655739  1.227233  1.121359  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Instantiate the scaler\n","scaler = StandardScaler()\n","\n","# Fit the scaler on the training data and transform both training and test data\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Display the first few rows of the normalized training data\n","pd.DataFrame(X_train, columns=X.columns).head()"]},{"cell_type":"markdown","metadata":{},"source":["## Fit a model\n","\n","- Instantiate `LogisticRegression`\n","  - Make sure you don't include the intercept  \n","  - set `C` to a very large number such as `1e12` \n","  - Use the `'liblinear'` solver \n","- Fit the model to the training data "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000000000000.0, fit_intercept=False, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000000000000.0, fit_intercept=False, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(C=1000000000000.0, fit_intercept=False, solver='liblinear')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Instantiate the model\n","logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n","\n","# Fit the model\n","logreg.fit(X_train, y_train)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Predict\n","Generate predictions for the training and test sets. "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Generate predictions\n","y_hat_train = logreg.predict(X_train)\n","y_hat_test = logreg.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["## How many times was the classifier correct on the training set?"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["195"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Calculate the number of correct predictions on the training set\n","correct_train_predictions = np.sum(y_hat_train == y_train)\n","correct_train_predictions\n"]},{"cell_type":"markdown","metadata":{},"source":["## How many times was the classifier correct on the test set?"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["63"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Calculate the number of correct predictions on the test set\n","correct_test_predictions = np.sum(y_hat_test == y_test)\n","correct_test_predictions\n"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis\n","Describe how well you think this initial model is performing based on the training and test performance. Within your description, make note of how you evaluated performance as compared to your previous work with regression."]},{"cell_type":"markdown","metadata":{},"source":["\n","Training Performance: Evaluate how well the model fits the training data. Common metrics include accuracy, precision, recall, F1-score for classification tasks, and mean squared error (MSE) or R-squared for regression tasks.\n","\n","Test Performance: Assess how well the model generalizes to unseen data. Use the same metrics as for the training performance to maintain consistency.\n","\n","Comparison with Previous Work: Compare the current model's performance with your previous regression models. Highlight any improvements or declines in performance metrics.\n","\n","Overfitting/Underfitting: Check for signs of overfitting (high training performance but low test performance) or underfitting (low performance on both training and test data)."]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","In this lab, you practiced a standard data science pipeline: importing data, split it into training and test sets, and fit a logistic regression model. In the upcoming labs and lessons, you'll continue to investigate how to analyze and tune these models for various scenarios."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":2}
